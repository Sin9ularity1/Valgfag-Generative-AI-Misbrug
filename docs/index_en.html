<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Home - GenAI Misuse in IT Security</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
    <nav>
        <div class="logo">Elective - Generative AI Misuse</div>
        <ul class="nav-links">
            <li><a href="index.html" class="active">Home</a></li>
            <li><a href="project.html">About the Project</a></li>
            <li><a href="labs.html">Labs</a></li>
            <li><a href="findings.html">Findings</a></li>
            <li><a href="logbog.html">Logbook</a></li>
            <li><a href="about.html">About</a></li>
        </ul>
    </nav>
</header>

<div class="container home-container">
    <aside class="sidebar home-sidebar">
        <h2>Navigation</h2>
        <ul>
            <li><a href="#home-summary">Purpose</a></li>
            <li><a href="#baggrund">Background and Delimitation</a></li>
            <li><a href="#problem-statement">Problem Statement</a></li>
            <li><a href="#key-highlights">Key Highlights</a></li>
            <li><a href="#Leverancer">Deliverables</a></li>
        </ul>
    </aside>

    <main>
    <section id="hero">
        <h1>Welcome to Elective - Generative AI Misuse in IT Security</h1>
        <p class="lead">Explore how advanced AI can be exploited for cyberattacks, and what can be done to defend ourselves.</p>
        <div class="call-to-action">
            <a href="project.html" class="button">Learn more about the Project</a>
            <br>
            <a href="labs.html" class="button">Explore our Labs</a>
        </div>
    </section>

    <section id="home-summary">
        <h2>Purpose</h2>
        <p>This project investigates the misuse of generative AI in cybersecurity, focusing on concrete attack techniques such as prompt injection, AI-supported phishing, and social engineering.</p>
        <p>The purpose is to identify central vulnerabilities in modern GenAI systems, analyze relevant attack vectors, and evaluate technical countermeasures with the aim of strengthening organizations' security in an AI-driven threat model.</p>
    </section>

    <section id="baggrund">
        <h2>Background and Delimitation</h2>
        <p>Developments in generative AI have raised broader concerns among researchers like Bengio, Hinton, and Hofstadter, particularly regarding responsible use and unknown long-term consequences. These discussions primarily fall under AI ethics and governance.</p>
        <p>However, this project is delimited to the technical cybersecurity dimension and focuses specifically on how generative AI systems can be misused through concrete attacks such as prompt injection, social engineering, and automated phishing.</p>
        <p>The purpose is not to assess existential risks, but to analyze practical security vulnerabilities and demonstrate realistic misuse scenarios that already pose a threat to organizations today.</p>
    </section>


    <section id="problem-statement">
        <h2>Problem Statement</h2>
        <p>Generative AI systems introduce new attack surfaces that traditional security models are not designed to handle. Techniques such as prompt injection, model misuse, and AI-supported social engineering allow attackers to bypass security controls and manipulate output in ways that can lead to data leaks, misinformation, and user compromise.</p>
        <p>The project's problem statement is therefore:</p>
        <ul>
            <li><strong>How can generative AI systems be misused in practice?</strong></li>
            <li><strong>Which central vulnerabilities can be identified through analysis and examples?</strong></li>
            <li><strong>Which technical countermeasures can be used to reduce the risk of these attacks?</strong></li>
        </ul>
        <p>The investigation is based on OWASP Top 10 for Large Language Models and combines literature review with illustrative scenarios and selected practical demonstrations.</p>
    </section>


    <section id="key-highlights">
        <h2>Key Highlights</h2>
        <div class="highlight-item">
            <h3>Practical Experiments</h3>
            <p>I have conducted hands-on experiments with real AI models to simulate and understand the attack mechanisms behind AI-generated malware, phishing emails, and prompt manipulation.</p>
            <p><a href="labs.html">See Labs for details.</a></p>
        </div>
        <div class="highlight-item">
            <h3>Research and Findings</h3>
            <p>Through in-depth analysis of AI's role in social engineering and identity misuse, I present findings and discuss the broader implications for IT security.</p>
            <p>I will conduct an in-depth analysis of AI's role in social engineering and identity misuse, presenting findings and discussing the broader implications for IT security.</p>
            <p><a href="findings.html">Read more about Findings.</a></p>
        </div>
    </section>

    <section id="Leverancer">
        <h2>Deliverables</h2>
        
    </section>
</main>
</div>

<footer>
    
</footer>

<script src="script.js"></script>
</body>
</html>