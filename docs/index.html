<!DOCTYPE html>
<html lang="da">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI & IT-sikkerhed Projekt</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<!-- NAVBAR -->
<header>
    <nav>
        <div class="logo">AI & IT-sikkerhed Projekt</div>
        <ul class="nav-links">
            <li><a href="index.html">Hjem</a></li>
            <li><a href="about.html">Om</a></li>
            <li><a href="logbog.html">Logbog</a></li>
        </ul>
    </nav>
</header>

<main>
    <section id="om">
        <h1>Velkommen</h1>
        <p>Velkommen til mit skoleprojekt omkring <strong>misbrug af generativ AI i IT-sikkerhed</strong>.</p>
        <p>Projektet undersøger, hvordan AI kan anvendes i cyberangreb som phishing, social engineering, malware-generering og prompt manipulation, og analyserer én valgt angrebstype dybdegående.</p>
    </section>

    <section id="teknologier">
        <h2>Fokusområder og teknologier</h2>
        <ul>
            <li>Analyse af AI-genereret phishing</li>
            <li>Social engineering ved brug af AI</li>
            <li>AI-assisteret malware</li>
            <li>Prompt injection og manipulation</li>
            <li>Deepfakes og identitetsmisbrug</li>
            <li>Automatiseret reconnaissance</li>
            <li>Python og eventuel lokal AI-model til demonstration</li>
        </ul>
    </section>

    <section id="maal">
        <h2>Projektmål</h2>
        <ul>
            <li>Undersøge hvordan generativ AI kan anvendes i cyberangreb</li>
            <li>Identificere centrale trusselsvektorer relateret til AI</li>
            <li>Analysere konkrete eksempler på AI-baseret misbrug</li>
            <li>Udvikle en simpel lokal AI-model som demonstrationsværktøj (valgfrit)</li>
            <li>Gennemføre en dybdegående analyse af én angrebstype</li>
            <li>Diskutere defensive strategier og modforanstaltninger</li>
        </ul>
    </section>

    <section id="milepaele">
        <h2>Milepæle og Tidsplan</h2>
        <table>
            <thead>
                <tr>
                    <th>Uge</th>
                    <th>Aktivitet</th>
                    <th>Output</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>1–2</td><td>Research: typer af AI-misbrug</td><td>Oversigt over trusler</td></tr>
                <tr><td>3–4</td><td>Indsamling og analyse af eksempler</td><td>Dokumentation af cases</td></tr>
                <tr><td>5–6</td><td>Valg af dybdegående angreb</td><td>Problemformulering og plan</td></tr>
                <tr><td>7–9</td><td>Teknisk analyse af valgt angrebstype</td><td>Rapport, diagrammer, skitser</td></tr>
                <tr><td>10–11</td><td>Valgfrit: Demonstration via lokal AI-model</td><td>Enkel AI-model</td></tr>
                <tr><td>12</td><td>Konklusion og defensive strategier</td><td>Endelig rapport og præsentation</td></tr>
            </tbody>
        </table>
    </section>

    <section id="metode">
        <h2>Metode</h2>
        <p>Projektet gennemføres som en kombination af analyse og praktisk demonstration. Fokus er på at forstå trusler, analysere eksempler og diskutere modforanstaltninger.</p>
        <ul>
            <li>Kortlægning af AI-misbrugsmetoder</li>
            <li>Teknisk analyse af én valgt angrebstype</li>
            <li>Demonstration via lokal AI-model (valgfrit)</li>
            <li>Løbende dokumentation og refleksion</li>
        </ul>

        <h3>Begrænsninger</h3>
        <p>Projektet er begrænset af tid, ressourcer og adgang til data. Fokus er på analyse og forståelse frem for udvikling af avancerede AI-systemer.</p>

        <h3>Ekstra Mål (Valgfrit)</h3>
        <ul>
            <li>Simulere forskellige angrebsscenarier</li>
            <li>Evaluere defensive strategier</li>
            <li>Skabe visualiseringer af AI-misbrug</li>
            <li>Reflektere over etiske aspekter</li>
        </ul>
    </section>

    <section id="læring">
        <h2>Overordnede Læringsmål</h2>
        <ul>
            <li>Forstå hvordan generativ AI kan misbruges i cyberangreb</li>
            <li>Analysere sikkerhedsrisici ved AI-systemer</li>
            <li>Identificere angrebsmetoder relateret til generativ AI</li>
            <li>Gennemføre teknisk analyse af én angrebstype</li>
            <li>Reflektere over defensive strategier</li>
            <li>Dokumentere et IT-sikkerhedsprojekt struktureret</li>
        </ul>
    </section>

    <section id="forfatter">
        <h2>Forfatter</h2>
        <p><strong>Reuben Badham</strong></p>
        <p>Uddannelse: IT-sikkerhed</p>
        <p>Lokation: Danmark</p>
        <p>Formål: Analysere AI-misbrug i cyberangreb og undersøge IT-sikkerhedsaspekter ved generativ AI</p>
    </section>
</main>

<footer>
    
</footer>

</body>
</html>
