<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Labs - GenAI Misuse in IT Security</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
    <nav>
        <div class="logo">Elective - Generative AI Misuse</div>
        <ul class="nav-links">
            <li><a href="index.html">Home</a></li>
            <li><a href="project.html">About the Project</a></li>
            <li><a href="labs.html" class="active">Labs</a></li>
            <li><a href="findings.html">Findings</a></li>
            <li><a href="logbog.html">Logbook</a></li>
            <li><a href="about.html">About</a></li>
        </ul>
    </nav>
</header>

<div class="page">
    <aside class="sidebar">
        <h2>Available Labs</h2>
        <ul>
        </ul>
    </aside>

        <section id="labs-home" class="content">
            <h1>Welcome to the Cybersecurity Labs</h1>
            <p>This section provides a comprehensive overview of various generative AI misuse scenarios in cybersecurity,
                focusing on the OWASP Top 10 for Large Language Models. Each lab delves into specific vulnerabilities,
                attack techniques, and potential countermeasures.</p>
            <p>Use the navigation on the left to explore individual labs and learn more about each vulnerability.</p>
            <div class="call-to-action">
                <a href="labs/prompt_injection.html" class="button">Start with Prompt Injection Lab</a>
            </div>
        </section>
</div>

<footer>
    
</footer>

<script src="script.js"></script>
</body>
</html>