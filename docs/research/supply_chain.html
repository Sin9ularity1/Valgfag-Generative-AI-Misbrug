<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM03: Supply Chain Vulnerabilities</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="manifest" href="../site.webmanifest">
</head>
<body>

<header>
    <nav>
        <div class="logo">GenAI Misuse in IT Security</div>
        <ul class="nav-links">
            <li><a href="../index.html">Home</a></li>
            <li><a href="../project.html">Project</a></li>
            <li><a href="../research.html" class="active">Research</a></li>
            <li><a href="../findings.html">Findings</a></li>
            <li><a href="../logbog.html">Logbook</a></li>
            <li><a href="../about.html">About</a></li>
        </ul>
    </nav>
</header>

<div class="page">
    <aside class="sidebar">
        <h2>Available Research</h2>
        <ul>
        </ul>
    </aside>
        
    <main class="content">
        <section>
            <h1>LLM03: Supply Chain Vulnerabilities</h1>

            <section>
                <h2>1. What is Supply Chain Vulnerability</h2>

                <p>
                    LLM Supply Chain Vulnerability refers to risks affecting the integrity of training data, pre-trained models, and deployment platforms<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP LLM03]</a></sup>. 
                    The supply chain for LLMs is complex and includes data scrapers, model providers, third-party libraries, and cloud infrastructure.
                </p>

                <p>
                    Vulnerabilities at any point in this chain can lead to biased outputs, security breaches, system failures, or the introduction of hidden backdoors into the model<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP LLM03]</a></sup>.
                </p>

                <p><strong>Potential impacts include:</strong></p>
                <ul>
                    <li>Compromise of model integrity and reliability<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup></li>
                    <li>Introduction of malicious backdoors or biases<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup></li>
                    <li>Legal and licensing risks from untrusted data/models<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup></li>
                    <li>Information disclosure or unauthorized system access<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup></li>
                </ul>
            </section>

            <section>
                <h2>2. Common Examples of Vulnerability</h2>

                <article>
                    <h3>2.1 Vulnerable Third-Party Packages</h3>
                    <p>Usage of outdated or compromised Python libraries (e.g., NumPy, PyTorch) during model development or deployment<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup>.</p>
                </article>

                <article>
                    <h3>2.2 Pre-trained Model Tampering</h3>
                    <p>Using models from untrusted sources that may contain hidden biases, backdoors, or have been fine-tuned to remove safety features<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup>.</p>
                </article>

                <article>
                    <h3>2.3 Data Poisoning in the Supply Chain</h3>
                    <p>Attackers compromising data sources used for training or fine-tuning, leading to manipulated model behavior<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup>.</p>
                </article>
            </section>

            <section>
                <h2>3. Prevention and Mitigation</h2>

                <p>
                    According to OWASP, securing the LLM supply chain requires a proactive and multi-layered approach<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP LLM03]</a></sup>.
                </p>

                <ul>
                    <li><strong>3.1 Vetting Sources:</strong> Rigorously vet all third-party data and pre-trained model sources. Only use reputable repositories.</li>
                    <li><strong>3.2 SBOM (Software Bill of Materials):</strong> Maintain an up-to-date SBOM to track all components, versions, and dependencies.</li>
                    <li><strong>3.3 Integrity Checks:</strong> Use cryptographic hashes and signatures to verify the integrity of models and datasets before use.</li>
                    <li><strong>3.4 Red Teaming:</strong> Conduct comprehensive AI Red Teaming to identify vulnerabilities and potential backdoors in integrated components.</li>
                    <li><strong>3.5 Least Privilege:</strong> Limit the permissions of models and tools within the environment to contain potential breaches.</li>
                </ul>
            </section>

            <section>
                <h2>4. Example Attack Scenarios</h2>
                <dl>
                    <dt>Scenario #1: Malicious Library Injection</dt>
                    <dd>An attacker compromises a popular ML library, injecting code that exfiltrates API keys during model training<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup>.</dd>
                    <dt>Scenario #2: Backdoored Pre-trained Model</dt>
                    <dd>A developer downloads a "fine-tuned" model from a public hub that contains a hidden trigger to bypass security checks<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup>.</dd>
                    <dt>Scenario #3: Poisoned Training Data</dt>
                    <dd>An attacker poisons a public dataset used for model alignment, causing the model to provide harmful instructions when specifically prompted<sup><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/" target="_blank">[OWASP]</a></sup>.</dd>
                </dl>
            </section>

            <section>
                <h2>5. References</h2>
                <ul>
                    <li><a href="https://genai.owasp.org/llmrisk/llm032025-supply-chain/">OWASP LLM03: Supply Chain Vulnerabilities</a></li>
                </ul>
            </section>
        </section>
    </main>
</div>

<footer>
</footer>

<script src="../script.js"></script>
</body>
</html>